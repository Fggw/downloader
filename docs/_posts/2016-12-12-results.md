---
layout: post
title:  "Results and Analysis"
published: true
page: 5
---

After implementing the processes described above, we found that AdaBoost (with 100 estimators) performed 
with the lowest average number of failure days, at 110 failure days.  This is about 40 failure days 
fewer that the actual order of inspections, which resulted in about 150 fail days. Other models like 
random forest with 45 features and adaboost with 50 estimators also performed well, averaging about 112 
fail days.  In analyzing this result, we were not surprised:  a boosted random forest is intuitive in 
this setting, considering several predictors were highly non-linear in the response.  In fact, looking 
at all of the best-performing models, they were either bagged or boosted tree ensemble methods.  


Ultimately, we satisfied the objective we set out to accomplish: we were able to output a ranked list of 
establishments for inspectors to inspect, in order, such that the number of days it takes them to 
inspect a failed establishment is lower on average than if they were randomly inspecting restaurants.  
Not only did we beat the baseline random inspection order by about 40 failure days, but we also beat the 
model that the city of chicago implemented.  In fact, they claimed to have improved inspection order by 
7 failure days.  Our model was thus 33 failure days or so better than Chicagoâ€™s model. We realize that 
this strong of an improvement is almost too good--this means that there are likely issues hidden in out 
model or over process.

