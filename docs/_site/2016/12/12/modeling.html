<!DOCTYPE html>
<html lang="en-us">
  
  <head>
  <meta charset="UTF-8">
  <title>Optimizing Food Inspections in Chicago</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/foodinspections/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/foodinspections/css/cayman.css">

    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

</head>

  <body>
    <section class="page-header">
  <h1 class="project-name">Optimizing Food Inspections in Chicago</h1>
  <h2 class="project-tagline">A Final Project for CS109a at Harvard University</h2>
  <a href="http://github.com/fggw/foodinspections/" class="btn">View on GitHub</a>
</section>

    <section class="main-content">
      
      






<center> <a href="/foodinspections/2016/12/12/data-exploration.html"> &#8592; Data Exploration</a> | <a href="/foodinspections/2016/12/12/results.html"> &#8594;</a> </center>



<h1>Modeling</h1>

<p>After developing some intuition with exploratory
analysis, we moved on to the modeling process.</p>

<h3 id="baseline">Baseline</h3>

<p>At first, it seemed that building a model that could take in the attributes of an establishment and 
predict whether or not it would fail was the optimal goal. However, given the nature 
of the problem we are trying to solve, 
prediction wasn’t the best objective to consider.</p>

<p>We aim to reduce the amount of time until a failed establishment is discovered. 
As a result, we decided to build ranking models so that inspectors could in practice
inspect from highest to lowest probability of failure.</p>

<p>We used log loss to select best performing 
models.</p>

<script type="math/tex; mode=display">l(p) = -\frac{1}{n} \sum y_i \log(p_i) - (1-y_i)\log(1 - p_i)</script>

<p>This choice was appropriate because log loss 
penalizes a probability’s distance from truth, rather than
a prediction’s distance from truth. For example,log loss strongly 
penalizes a case in which a model gave an establishment a 
high probability of passing an inspection when it actually 
ends up failing.</p>

<p>Since this was more nuanced than a problem of prediction, an appropriate scoring approach (e.g. log loss) was more important than selecting a single optimal model. We considered several classes of classifiers - logistic regression, linear and quadratic discriminant analysis, bagging approaches like random forests, boosting approaches like AdaBoost, and so on. To select a single ‘best’ model per class, we ran 5-fold cross-validation to search exhaustively over and score by log loss a range of reasonable sets of hyper-parameters, ultimately arriving at a best model per model class.</p>

<p>Given our objective of the project, we decided to select models, via cross validation, based on a metric 
we call “failure days.”  Failure days represent the aggregated number of days it takes, from the start 
of the first inspection in a given time frame, to inspect (and fail) a health-violating establishment.<br />
For illustration, note the following simple example.  Imagine an inspector is inspecting 10 restaurants 
in the first week of february.  It turns out that 2 of the establishments end up failing while the rest 
pass.  If the inspector inspected the failed establishments on day 2 and day 3 of the week, the failure 
days would be 2 + 3 = 5 failure days.  However, if the inspector inspected the failed establishments on 
day 4 and day 6 of the week, the failure days would be 4 + 6 = 10.  Thus, in this simple case, we would 
select the model that resulted in 5 failure days rather than the one that resulted in 10 failure days.<br />
By choosing the model that minimizes failure days,we get a ranked list that enables inspectors to 
inspect, in a given time frame, establishments likely to fail sooner than ones likely to pass.</p>

<p>One consideration that proved important in the model building process was the following:  one has to 
think about how often inspectors should receive a new list of ranked establishments to inspect.  In 
other words, should inspectors receive a new ranked list of establishments every week, month, or three 
months?  Is there an optimal time interval for which a new list should be generated? These were 
considerations we had to take into account in the model scoring phase of our process.  We ended up not 
picking a regeneration interval for the ranked lists–rather, we just used log loss to rank the entire 
test set at once.  In future projects, it may be telling to test different list regeneration intervals 
to see if our overall results could be improved.</p>

<p>In summary, in the model scoring phase, our models feed lists of probabilities to a log loss 
function–these probabilities represent the likelihood of an establishment to fail based on a set of 
different predictors.  Log loss then scores the models, strongly penalizing cases of low probability of 
failure if the result of the inspection turns out to be actually be a failure. Each inspection in the 
list is then officially assigned a “1” or “0” for “pass” or “fail.” Finally, we use these lists or 
ordered passes and fails to measure the number of failure days (using cross validation) of each model, 
which is the aggregate number of days from the first day of inspections to each failed inspection.</p>



<br>


<center> <a href="/foodinspections/2016/12/12/data-exploration.html"> &#8592; Data Exploration</a> | <a href="/foodinspections/2016/12/12/results.html"> &#8594;</a> </center>






      <footer class="site-footer">
  <span class="site-footer-owner"><a href="http://localhost:4000/foodinspections/">Optimizing Food Inspections in Chicago</a> was created for CS109a by: 
    <ul> 
    
        <li><a href="http://no.website">Luke Farewell</a></li>
    
        <li><a href="http://no.website">Jake Gober</a></li>
    
        <li><a href="http://sa.muel.green">Samuel Green</a></li>
    
        <li><a href="http://no.website">Jeremy Welborn</a></li>
    
    </ul>

  <span class="site-footer-owner">We were advised by <a href="https://github.com/tnames">Taylor Names.
</footer>


    </section>

  </body>
</html>
