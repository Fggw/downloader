<!DOCTYPE html>
<html lang="en-us">
  
  <head>
  <meta charset="UTF-8">
  <title>Optimizing Food Inspections in Chicago</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/foodinspections/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/foodinspections/css/cayman.css">

    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

</head>

  <body>
    <section class="page-header">
  <h1 class="project-name">Optimizing Food Inspections in Chicago</h1>
  <h2 class="project-tagline">A Final Project for CS109a at Harvard University</h2>
  <a href="http://github.com/fggw/foodinspections/" class="btn">View on GitHub</a>
</section>

    <section class="main-content">
      
      






<center> <a href="/foodinspections/2016/12/12/modeling.html"> &#8592; Modeling</a> | <a href="/foodinspections/2016/12/12/conclusion.html">Conclusion &#8594;</a> </center>



<h1>Results and Analysis</h1>

<p>After implementing the processes described above, we found that AdaBoost (with 100 estimators) performed 
with the lowest average number of failure days, at 110 failure days.  This is about 40 failure days 
fewer that the actual order of inspections, which resulted in about 150 fail days. Other models like 
random forest with 45 features and adaboost with 50 estimators also performed well, averaging about 112 
fail days.  In analyzing this result, we were not surprised:  a boosted random forest is intuitive in 
this setting, considering several predictors were highly non-linear in the response.  In fact, looking 
at all of the best-performing models, they were either bagged or boosted tree ensemble methods.</p>

<p>Ultimately, we satisfied the objective we set out to accomplish: we were able to output a ranked list of 
establishments for inspectors to inspect, in order, such that the number of days it takes them to 
inspect a failed establishment is lower on average than if they were randomly inspecting restaurants.<br />
Not only did we beat the baseline random inspection order by about 40 failure days, but we also beat the 
model that the city of chicago implemented.  In fact, they claimed to have improved inspection order by 
7 failure days.  Our model was thus 33 failure days or so better than Chicago’s model. We realize that 
this strong of an improvement is almost too good–this means that there are likely issues hidden in out 
model or over process.</p>



<br>


<center> <a href="/foodinspections/2016/12/12/modeling.html"> &#8592; Modeling</a> | <a href="/foodinspections/2016/12/12/conclusion.html">Conclusion &#8594;</a> </center>




      <footer class="site-footer">
  <span class="site-footer-owner"><a href="http://localhost:4000/foodinspections/">Optimizing Food Inspections in Chicago</a> was created for CS109a by: 
    <ul> 
    
        <li><a href="http://no.website">Luke Farewell</a></li>
    
        <li><a href="http://no.website">Jake Gober</a></li>
    
        <li><a href="http://sa.muel.green">Samuel Green</a></li>
    
        <li><a href="http://no.website">Jeremy Welborn</a></li>
    
    </ul>

  <span class="site-footer-owner">We were advised by <a href="https://github.com/tnames">Taylor Names.
</footer>


    </section>

  </body>
</html>
