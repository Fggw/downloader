<!DOCTYPE html>
<html lang="en-us">
  
  <head>
  <meta charset="UTF-8">
  <title>Optimizing Food Inspections in Chicago</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/foodinspections/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/foodinspections/css/cayman.css">
</head>

  <body>
    <section class="page-header">
  <h1 class="project-name">Optimizing Food Inspections in Chicago</h1>
  <h2 class="project-tagline">A Final Project for CS109a at Harvard University</h2>
  <a href="http://github.com/fggw/foodinspections/" class="btn">View on GitHub</a>
</section>

    <section class="main-content">
      
      






<center> <a href="/foodinspections/2016/12/12/data-cleaning.html"> Data Collection and Cleaning &#8594;</a> </center>



<h1>Introduction</h1>

<p>In the city of Chicago, only 36 inspectors are tasked with inspecting over 15,000 establishments.  Typically, the order in which inspectors inspect different establishments is arbitrary and does not target ones that are likely to have critical health violations.  This means that some establishments could go months without being inspected, even if they are extremely likely to fail.  For every day that an establishment with hazardous health conditions goes uninspected, city goers are put at risk because they have no idea that said establishment is not safe.</p>

<p>Given this problem in a major city, the City of Chicago set out to use data science methods and try to find establiments most likely to fail inspections.  How did they do this?  By using open source data from the Chicago local government with attributes of the city’s many establishments combined with past inspection results data, the team set out to rank establishments in order of most-likely to fail to least-likely-to-fail. This now meant that, rather than inspectors arbitrarily inspecting establishment after establishment, they could start with those most likely to fail.  This method worked: in fact, after ranking restaurants in the aforementioned fashion, inspectors found failed establishments seven days earlier than they had before when not using a ranked list.</p>

<p>Our project set out to improve upon the Chicago model and thus improve the rate at which inspectors can find establishments hazardous to city goer health.  Using attributes of establishments in the city, past inspection data, and data on local weather, we built a model that ranks a year’s worth of future inspections in order of most-likely-to-fail to least-likely-to-fail.  We then found our model to perform [x] better than the Chicago’s  model.</p>


<br>


<center> <a href="/foodinspections/2016/12/12/data-cleaning.html"> Data Collection and Cleaning &#8594;</a> </center>




      <footer class="site-footer">
  <span class="site-footer-owner"><a href="http://localhost:4000/foodinspections/">Optimizing Food Inspections in Chicago</a> was created for CS109a by: 
    <ul> 
    
        <li><a href="http://no.website">Luke Farewell</a></li>
    
        <li><a href="http://no.website">Jake Gober</a></li>
    
        <li><a href="http://sa.muel.green">Samuel Green</a></li>
    
        <li><a href="http://no.website">Jeremy Welborn</a></li>
    
    </ul>

  <span class="site-footer-owner">We were advised by <a href="https://github.com/tnames">Taylor Names.
</footer>


    </section>

  </body>
</html>
