{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Imputation and Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data and desired features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../data_built_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in data.columns.values:\n",
    "    print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we should return to this and check which covariates we've selected \n",
    "\n",
    "cols = ['inspection_date',\n",
    "        'facility_type',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'results',\n",
    "        'risk',\n",
    "        'business_activity_Consumption of Liquor on Premises',\n",
    "        'business_activity_Preparation of Food and Dining on Premise With Seating',\n",
    "        'business_activity_Retail Sale of Tobacco',\n",
    "        'business_activity_Retail Sales of Packaged Liquor',\n",
    "        'business_activity_Retail Sales of Perishable Foods',\n",
    "        'Canvass', # inspection_type\n",
    "        'License',\n",
    "        'Canvass Re-Inspection',\n",
    "        'Complaint',\n",
    "        'License Re-Inspection',\n",
    "        'Short Form Complaint',\n",
    "        'Complaint Re-Inspection',\n",
    "        'Suspected Food Poisoning',\n",
    "        'Consultation',\n",
    "        'License-Task Force',\n",
    "        'point_crime_count',\n",
    "        'point_sanit_count',\n",
    "        'result_binary',\n",
    "        'TMAX',\n",
    "        'TMAX_3DayAvg',\n",
    "        'TMAX_10DayAvg',\n",
    "        'TMAX_30DayAvg',\n",
    "        'previous_count',\n",
    "        'previous_fraction',\n",
    "        'previous_result',\n",
    "        'time_since_last_inspection',\n",
    "        'previous_violations',\n",
    "        'previous_citations',\n",
    "        'previous_critical',\n",
    "        'previous_serious',\n",
    "        'previous_minor',\n",
    "        'previous_corrected']\n",
    "\n",
    "print data[cols].shape\n",
    "print data.shape\n",
    "\n",
    "# select specific features\n",
    "data_sub = data[cols]\n",
    "# what would happen if we dropped NaNs\n",
    "print data_sub.dropna(axis=0, how='any').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sub = data_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temporary -- dumping correct crime data and sanitation complaint data into dataset\n",
    "data_dump = pd.read_csv('../data_with_crime_sanit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_sub['crime'] = data_dump['crime'].copy()\n",
    "data_sub['sanit'] = data_dump['sanitation'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert string to datetime to be safe\n",
    "data_sub['inspection_date'] = pd.to_datetime(data_sub['inspection_date'])\n",
    "\n",
    "print data_sub['inspection_date'].min()\n",
    "print data_sub['inspection_date'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation and encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# non-KNN approach:\n",
    "# replace null values with feature mean (quantitative) or feature mode (qualitative)\n",
    "# for column in data_sub.columns:\n",
    "#     if (data_sub[column].unique().shape[0] < 8) or (data_sub[column].dtype == np.dtype('object')):\n",
    "#         data_sub[column].fillna(value = data_sub[column].mode()[0], inplace = True)\n",
    "#     else:\n",
    "#         data_sub[column].fillna(value = data_sub[column].mean(), inplace = True)\n",
    "\n",
    "# check no null values\n",
    "nan_cnt = 0\n",
    "for i, column in enumerate(data_sub.columns):\n",
    "    print i, column, np.array(data_sub[column].isnull()).sum()\n",
    "    nan_cnt = nan_cnt + np.array(data_sub[column].isnull()).sum()\n",
    "    \n",
    "print 'total cells:', data_sub.size\n",
    "print 'nan_cnt:', nan_cnt\n",
    "print 'ratio for sam:', nan_cnt / float(data_sub.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how should we handle the historical count data?\n",
    "# there's no optimal solution: either (1) impute, biasing that they wouldn't have done well \n",
    "# or (2) set to 0, biasing that they would've done well? We'll set to 0 for simplicity.\n",
    "\n",
    "print 'count of obs for which previous_count == 0:', data_sub[data_sub['previous_count'] == 0.0].shape[0]\n",
    "print 'this corresponds with number of nans for previous_fraction, previous_result, time_since_last_inspection, which is what we\\'d expect'\n",
    "\n",
    "# set all these to 0 then\n",
    "hist_cols = ['previous_fraction',\n",
    "            'previous_result',\n",
    "            'time_since_last_inspection',\n",
    "            'previous_violations',\n",
    "            'previous_citations',\n",
    "            'previous_critical',\n",
    "            'previous_serious',\n",
    "            'previous_minor',\n",
    "            'previous_corrected']\n",
    "\n",
    "for hist_col in hist_cols:\n",
    "    data_sub.loc[data_sub['previous_count'] == 0.0, hist_col] = data_sub.loc[data_sub['previous_count'] == 0.0, hist_col].fillna(value = 0)\n",
    "    \n",
    "print '\\n here are NaN counts after this step: \\n'\n",
    "for i, column in enumerate(data_sub.columns):\n",
    "    print i, column, np.array(data_sub[column].isnull()).sum()\n",
    "    \n",
    "print '37-42 still have a uniform number of null values because they had no text from the inspection, so nothing to scrape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# obs with no null values\n",
    "print 'count of obs with no null values:', data_sub.shape[0] - data_sub.isnull().any(axis = 1).sum()\n",
    "print 'count of features with no null values:', data_sub.shape[1] - data_sub.isnull().any(axis = 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features with no null values we can use to impute\n",
    "data_sub.isnull().any(axis = 0)[data_sub.isnull().any(axis = 0) == False].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# so that the imputer has enough predictors, to work with, fill in risk by mean / mode approach since only 63 obs have nulls\n",
    "\n",
    "data_sub['risk'].fillna(value = data_sub['risk'].mode()[0], inplace = True)\n",
    "\n",
    "# same\n",
    "# data_sub['inspection_type'].fillna(value = data_sub['inspection_type'].mode()[0], inplace = True)\n",
    "\n",
    "# check\n",
    "print 'number of null values in risk:', data_sub['risk'].isnull().sum()\n",
    "# print 'number of null values in inspection_type:', data_sub['inspection_type'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KNN \n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have to encode the data first... but facility_type is annoying to do...\n",
    "print data_sub.facility_type.value_counts()[0:10]\n",
    "\n",
    "take_types = data_sub.facility_type.value_counts()[0:50].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# why don't we just take the first fifty for now \n",
    "# this takes awhile... a faster approach?\n",
    "#\n",
    "# READ THIS IN, DONT BOTHER RUNNING AGAIN\n",
    "#\n",
    "for i, row in data_sub[['facility_type']].iterrows():\n",
    "    if row.values not in take_types:\n",
    "        data_sub.loc[i, 'facility_type'] = 'Other'\n",
    "    else:\n",
    "        continue\n",
    "    if (i % 500 == 0):\n",
    "        print 'finished iteration:', i\n",
    "        \n",
    "        \n",
    "# it's encoded in this, so just kidding\n",
    "# hack_data = data = pd.read_csv('../data_ready.csv')\n",
    "# hack_data['facility_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check response\n",
    "print 'Useless response count:', sum((data_sub.results != 'Pass') & (data_sub.results != 'Pass w/ Conditions') & (data_sub.results != 'Fail'))\n",
    "indices = (data_sub.results == 'Pass') | (data_sub.results == 'Pass w/ Conditions') | (data_sub.results == 'Fail')\n",
    "data_sub = data_sub[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# risk\n",
    "indices = (data_sub.risk == 'Risk 1 (High)') | (data_sub.risk == 'Risk 2 (Medium)') | (data_sub.risk == 'Risk 3 (Low)')\n",
    "data_sub = data_sub[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sub = data_sub.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have to these encode first\n",
    "data_sub_encoded = pd.DataFrame({})\n",
    "for column in data_sub.columns:\n",
    "#     if (data_sub[column].unique().shape[0] < 8) or data_sub[column].dtype == np.dtype('object'):\n",
    "    if (data_sub[column].dtype == np.dtype('object')) & (column not in ['results']):\n",
    "        encoding = pd.get_dummies(data_sub[column])\n",
    "        data_sub_encoded = pd.concat([data_sub_encoded, encoding], axis = 1)\n",
    "    else:\n",
    "#         data_sub_encoded = pd.concat([data_sub_encoded, data_sub[[column]].astype(float)], axis = 1)\n",
    "        data_sub_encoded = pd.concat([data_sub_encoded, data_sub[[column]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train data are observations that are complete\n",
    "# test data (which we wish to impute) are observations that are incomplete\n",
    "train = data_sub_encoded[np.logical_not(data_sub_encoded.isnull().any(axis = 1).values)]\n",
    "test = data_sub_encoded[data_sub_encoded.isnull().any(axis = 1).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset indices because we've dropped rows, NearestNeighbors was returning wrong indices because they weren't reset\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dont actually have to split x and y since we specify what features we're imputing on in impute_cols\n",
    "# x_train = train.drop(['result_binary', 'results'], axis = 1) \n",
    "# x_test = test.drop(['result_binary', 'results'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_sub.isnull().any(axis = 0)[data_sub.isnull().any(axis = 0) == False].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should be using 'inspection_type', facility_type' too but i will return to this, was frustrated with the encoding!\n",
    "# these have to be encoded to work with knn, but when encoded it is hard to get them...\n",
    "\n",
    "impute_cols = ['Risk 1 (High)', 'Risk 2 (Medium)', 'Risk 3 (Low)', 'previous_count', 'previous_fraction',\n",
    "       'previous_result', 'time_since_last_inspection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(n_neighbors = 5)\n",
    "knn.fit(train[impute_cols]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return k nearest neighbors based on features we have for all observations\n",
    "# then fill in other values using these nearest neighbors \n",
    "\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "for i, row in test.iterrows(): # for each observation with incomplete features\n",
    "    ind = knn.kneighbors(X = row[impute_cols].values.reshape(1,-1), return_distance=False)[0] # return indices of nearest neighbors with complete features\n",
    "    for col in test.columns.values[row.isnull().values]: # for each feature that're NaNs    \n",
    "        train_vals = np.array(train.loc[ind, col]) # get vals from nearest neighbors for this col\n",
    "        if train[col].unique().shape[0] <= 2: # if indicator \n",
    "            test.loc[i, col] = stats.mode(train_vals)[0][0] # fill w/ mode\n",
    "        else:\n",
    "            test.loc[i, col] = train_vals.mean() # fill w/ mean\n",
    "    if (i % 500 == 0):\n",
    "        print 'finished iteration:', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this won't work, apply flattens the thing\n",
    "# import math\n",
    "# from scipy import stats\n",
    "\n",
    "# def impute_row(row):\n",
    "#     ind = knn.kneighbors(X = row[impute_cols].values.reshape(1, -1), return_distance=False)[0]\n",
    "#     for col in test.columns.values[row.isnull().values]: # for each feature that're NaNs    \n",
    "#         train_vals = np.array(train.loc[ind, col])\n",
    "#         if train[col].unique().shape[0] <= 2:\n",
    "#             row[col] = stats.mode(train_vals)[0][0]\n",
    "#         else:\n",
    "#             row[col] = train_vals.mean()\n",
    "\n",
    "# test = test.apply(impute_row, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ready = pd.concat([train, test], axis = 0)\n",
    "data_ready = data_ready.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reorder = ['inspection_date','result_binary','results','point_crime_count', 'point_sanit_count',\n",
    "#       'latitude', 'longitude','TMAX','TMAX_3DayAvg', 'TMAX_10DayAvg', 'TMAX_30DayAvg',\n",
    "#      'Risk 1 (High)', 'Risk 2 (Medium)', 'Risk 3 (Low)',\n",
    "#         'previous_count','previous_fraction', 'previous_result',\n",
    "#        'time_since_last_inspection', 'previous_violations',\n",
    "#        'previous_citations', 'previous_critical', 'previous_serious',\n",
    "#        'previous_minor', 'previous_corrected','inspection_type',\n",
    "#         \"1023 CHILDERN'S SERVICES FACILITY\",\n",
    "#        \"1023-CHILDREN'S SERVICES FACILITY\", 'ASSISTED LIVING', 'BANQUET',\n",
    "#        'BANQUET HALL', 'Bakery', 'CAFETERIA', 'CHURCH', 'CHURCH KITCHEN',\n",
    "#        'CONVENIENCE', 'CONVENIENCE STORE', 'CULINARY SCHOOL', 'Catering',\n",
    "#        \"Children's Services Facility\", 'DAYCARE', 'Daycare (2 - 6 Years)',\n",
    "#        'Daycare (2 Years)', 'Daycare (Under 2 Years)',\n",
    "#        'Daycare Above and Under 2 Years', 'Daycare Combo 1586',\n",
    "#        'GAS STATION', 'GAS STATION/MINI MART', 'GROCERY/RESTAURANT',\n",
    "#        'Golden Diner', 'Grocery Store', 'Hospital', 'KIOSK',\n",
    "#        'LIVE POULTRY', 'Liquor', 'Long Term Care', 'Mobile Food Dispenser',\n",
    "#        'Mobile Food Preparer', 'Navy Pier Kiosk', 'Other',\n",
    "#        'PRIVATE SCHOOL', 'RESTAURANT/BAR', 'RESTAURANT/GROCERY STORE',\n",
    "#        'ROOF TOPS', 'ROOFTOP', 'Restaurant', 'STADIUM', 'STORE', 'School',\n",
    "#        'Shared Kitchen', 'Shared Kitchen User (Long Term)',\n",
    "#        'Shared Kitchen User (Short Term)', 'Shelter', 'Special Event',\n",
    "#        'TAVERN', 'Wholesale', 'convenience store', \n",
    "#        'business_activity_Catering of Liquor To Events',\n",
    "#        'business_activity_Consumption of Liquor on Premises',\n",
    "#        'business_activity_Hotel - 7 or More Sleeping Rooms',\n",
    "#        'business_activity_Operation of a Fuel Filling Station',\n",
    "#        'business_activity_Preparation of Food and Dining on Premise With Seating',\n",
    "#        'business_activity_Provides Onsite Amusement or Entertainment',\n",
    "#        'business_activity_Retail Sale of Tobacco',\n",
    "#        'business_activity_Retail Sales of Packaged Liquor',\n",
    "#        'business_activity_Retail Sales of Packaged Liquor on Sundays from 8AM - 11AM | Retail Sales of Packaged Liquor',\n",
    "#        'business_activity_Retail Sales of Packaged Liquor | Retail Sales of Packaged Liquor on Sundays from 8AM - 11AM',\n",
    "#        'business_activity_Retail Sales of Perishable Foods',\n",
    "#        'business_activity_Retail Sales of Tobacco Products',\n",
    "#        'business_activity_Sale of Food Prepared Onsite With Dining Area',\n",
    "#        'business_activity_Sale of Food Prepared Onsite Without Dining Area',\n",
    "#        'business_activity_Sale of Liquor Outdoors on Private Property',\n",
    "#        'business_activity_Sale of Liquor Until 4am, Monday - Saturday and 5am on Sunday',\n",
    "#        'business_activity_Supervision of, and Care for, Children 0-6 Years of Age, During the Day Between 6am-9pm',\n",
    "#        'business_activity_Supervision of, and Care for, Children 2-6 Years of Age, During the Day Between 6am-9pm',\n",
    "#        'business_activity_Supervision of, and Care for, Children Under 2 Years of Age, During the Day Between 6am-9pm | Supervision of, and Care for, Children 2-6 Years of Age, During the Day Between 6am-9pm',\n",
    "#        'business_activity_Tavern - Consumption of Liquor on Premise']\n",
    "\n",
    "# data_ready = data_ready[reorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# so don't have to rerun the code above\n",
    "data_ready.to_csv('/Users/jeremywelborn1/Documents/Jeremy/Harvard/Classes/III_Junior/1st_CS109a/fggw/data_ready.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
